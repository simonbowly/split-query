{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import functools\n",
    "import logging\n",
    "import pandas as pd\n",
    "from frozendict import frozendict\n",
    "\n",
    "from octo_spork.simplify import simplify\n",
    "from octo_spork.expressions import And, Or, Not, Le, Lt, Ge, Gt, Attribute\n",
    "from octo_spork.logic import to_dnf, to_cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_query_df(df, query):\n",
    "    ''' Pandas engine implementation applying a query to a dataframe.\n",
    "    Returns an index on the dataframe.\n",
    "    TODO implement NOT and test things. '''\n",
    "    if query.expr == 'le':\n",
    "        return df[query.attribute.name] <= query.value\n",
    "    if query.expr == 'ge':\n",
    "        return df[query.attribute.name] >= query.value\n",
    "    if query.expr == 'lt':\n",
    "        return df[query.attribute.name] < query.value\n",
    "    if query.expr == 'gt':\n",
    "        return df[query.attribute.name] > query.value\n",
    "    if query.expr == 'and':\n",
    "        return functools.reduce(\n",
    "            lambda ind1, ind2: ind1 & ind2,\n",
    "            (map_query_df(df, clause) for clause in query.clauses))\n",
    "    if query.expr == 'or':\n",
    "        return functools.reduce(\n",
    "            lambda ind1, ind2: ind1 | ind2,\n",
    "            (map_query_df(df, clause) for clause in query.clauses))\n",
    "\n",
    "def query_df(df, query):\n",
    "    ''' Use index from map_query_df to return filtered dataframe. '''\n",
    "    if query is None:\n",
    "        return df\n",
    "    return df[map_query_df(df, query)]\n",
    "\n",
    "def decompose(query, cached_query):\n",
    "    ''' Find intersection to filter the cached data and remainder specifying\n",
    "    any data missing from the cache. '''\n",
    "    return (\n",
    "        to_dnf(simplify(to_dnf(And([query, cached_query])))),         # intersection\n",
    "        to_dnf(simplify(to_dnf(And([query, Not(cached_query)])))))    # remainder\n",
    "\n",
    "def resolve_cache_steps(cache, query):\n",
    "    ''' Step through cached queries, sequentially removing contributions. '''\n",
    "    for cached_query, cached_data in cache.items():\n",
    "        cached_intersection, cached_remainder = decompose(query, cached_query)\n",
    "        if cached_intersection is not False:\n",
    "            logging.warning('Use cache: {}'.format(repr(cached_query)))\n",
    "            yield query_df(cached_data, cached_intersection), cached_remainder\n",
    "        query = cached_remainder\n",
    "        if query is False:\n",
    "            break\n",
    "\n",
    "def resolve_cache(cache, query):\n",
    "    ''' Resolve as much as possible over the cache, returning partial datasets\n",
    "    and a query object specifying the remainder. '''\n",
    "    remainder = query\n",
    "    datasets = []\n",
    "    for dataset, remainder in resolve_cache_steps(cache, query):\n",
    "        datasets.append(dataset)\n",
    "    return datasets, remainder\n",
    "\n",
    "def resolve_update_cache(cache, query, remote):\n",
    "    ''' Resolve over the cache, run the remainder query on the given remote,\n",
    "    adding its result to the cache. '''\n",
    "    datasets, remainder = resolve_cache(cache, query)\n",
    "    remainder = to_dnf(simplify(to_dnf(remainder)))\n",
    "    if remainder is False:\n",
    "        return pd.concat(datasets)\n",
    "    cache[remainder] = remote.get(remainder)\n",
    "    if len(datasets) == 0:\n",
    "        return cache[remainder]\n",
    "    return pd.concat(datasets + [cache[remainder]])\n",
    "\n",
    "def to_recordset(df):\n",
    "    return set(frozendict(row) for _, row in df.iterrows())\n",
    "\n",
    "def results_equal(df1, df2):\n",
    "    return to_recordset(df1) == to_recordset(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_full_df = pd.DataFrame(\n",
    "    columns=['a', 'b', 'c', 'ind'],\n",
    "    data=[\n",
    "        (x, y, z, ind) for ind, (x, y, z) in\n",
    "        enumerate(itertools.product(range(10), range(10), range(10)))])\n",
    "\n",
    "\n",
    "class RemoteDataSource(object):\n",
    "    ''' Static data source ('remote' part): columns, dataframe, etc '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.a, self.b, self.c = [Attribute(name) for name in 'abc']\n",
    "\n",
    "    def get(self, query):\n",
    "        logging.warning('Use remote: {}'.format(repr(query)))\n",
    "        return query_df(_full_df, query)\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "    ''' The interface part allowing for querying. Indexing with a query returns a\n",
    "    new Dataset with the same remote, cache, and info, with the query appended to\n",
    "    any existing query constants (joined with And to get intersection). '''\n",
    "\n",
    "    def __init__(self, remote, cache, desc, columns, query=None):\n",
    "        self._remote = remote\n",
    "        self._cache = cache\n",
    "        self._desc = desc\n",
    "        self._columns = {c: Attribute(c) for c in columns}\n",
    "        self._query = query\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}\\nColumns: {}\\nFilter: {}'.format(\n",
    "            self._desc, ', '.join(self._columns.keys()),\n",
    "            repr(self._query))\n",
    "\n",
    "    def __getattr__(self, col):\n",
    "        if col in self._columns:\n",
    "            return self._columns[col]\n",
    "        raise AttributeError('\\'{}\\' object has no attribute \\'{}\\''.format(\n",
    "            self.__class__.__name__, col))\n",
    "\n",
    "    def __getitem__(self, query):\n",
    "        if self._query is not None:\n",
    "            query = And([self._query, query])\n",
    "        return Dataset(\n",
    "            remote=self._remote, cache=self._cache, desc=self._desc,\n",
    "            columns=self._columns.keys(), query=query)\n",
    "\n",
    "    def get(self):\n",
    "        ''' Run the current query. '''\n",
    "        return resolve_update_cache(\n",
    "            cache=self._cache, query=self._query, remote=self._remote)\n",
    "\n",
    "# This base object has a clean cache, filtered datasets will be derived from it.\n",
    "data = Dataset(\n",
    "    remote=RemoteDataSource(), cache=dict(), columns='abc',\n",
    "    desc='Really simple 3D data source.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Blank cache, query is passed to remote.\n",
    "data1 = data[Ge(data.b, 8)][Le(data.c, 0)][And([Ge(data.a, 2), Le(data.a, 4)])]\n",
    "print(data1)\n",
    "data1.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeated query, only the cache is used.\n",
    "data2 = data[Ge(data.b, 8)][Le(data.c, 0)][And([Ge(data.a, 2), Le(data.a, 4)])]\n",
    "print(data2)\n",
    "data2.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded query. Cache is used but an additional remote call must be made.\n",
    "data3 = data[Ge(data.b, 8)][Le(data.c, 0)][And([Ge(data.a, 2), Le(data.a, 6)])]\n",
    "print(data3)\n",
    "data3.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded query. Cache is used but an additional remote call must be made.\n",
    "data4 = data[Ge(data.b, 8)][Le(data.c, 0)][And([Ge(data.a, 1), Le(data.a, 7)])]\n",
    "print(data4)\n",
    "data4.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verified things were correctly assembled by comparing with a source pull.\n",
    "remote = RemoteDataSource()\n",
    "logging.warning(results_equal(data1.get(), remote.get(data1._query)))\n",
    "logging.warning(results_equal(data2.get(), remote.get(data2._query)))\n",
    "logging.warning(results_equal(data3.get(), remote.get(data3._query)))\n",
    "logging.warning(results_equal(data4.get(), remote.get(data4._query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
